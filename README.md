# Headline Generation

In the world of digital media, when millions of news articles are competing for readers’ eyeballs everyday, headlines play an important role in guiding readers to find the right content to focus on. Because of this, some publishers are incentivised to create headlines with misleading content only to catch readers’ attention. Thus, developing an automatic headline generation system that can provide an honest and informative headline from an article becomes a critical challenge. This paper investigates different abstractive text summarization frameworks, including a statistical model introduced in 2000 and a Transformer-based deep learning model developed in 2020, to understand the benefits and limitations of these approaches. Our contributions to this project include 1) implementing and evaluating these models on the recently published dataset, NewSHead and 2) experimenting with new pre-training and adaptation strategies to improve upon the Transformer-based encoder-decoder model.
