{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_to_list(s):\n",
    "    end = s.replace('[', '').replace(']', '').replace('\\'', '').replace(' ', '').split(',')\n",
    "    return end\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(os.path.join('..', 'data', filename))\n",
    "    df.body = df.body.apply(lambda x: back_to_list(x))\n",
    "    df.title = df.title.apply(lambda x: back_to_list(x))\n",
    "    return df\n",
    "\n",
    "def generate_vocab(df, include_headline=True, include_body=False):\n",
    "    vocab = set()\n",
    "    for row in df.title:\n",
    "        vocab = vocab.union(set(row))\n",
    "    if include_body:\n",
    "        for row in df.body:\n",
    "            vocab = vocab.union(set(row))       \n",
    "    vocab = list(vocab)\n",
    "    print(f'Vocab Size: {len(vocab)}')\n",
    "    return vocab\n",
    "\n",
    "def p_w_H_given_D(df, vocab):\n",
    "    # denominator, numerator\n",
    "    p_w_in_D, p_w_in_HD = {}, {}\n",
    "    for word in tqdm(vocab):\n",
    "        dcount, hdcount = 1, 1\n",
    "        for article in df.iterrows():\n",
    "            if word in article[1].body:\n",
    "                dcount += 1\n",
    "                if word in article[1].title:\n",
    "                    hdcount += 1\n",
    "        p_w_in_D[word] = dcount\n",
    "        p_w_in_HD[word] = hdcount\n",
    "    return {word: p_w_in_HD[word] / p_w_in_D[word] for word in vocab}\n",
    "\n",
    "def length_prob(df):\n",
    "    length_list = [len(headline) for headline in df.title]\n",
    "    length_counter = Counter(length_list)\n",
    "    return {length: count/len(length_list) for length, count in length_counter.items()}\n",
    "\n",
    "def freq_to_prob(whole, item):\n",
    "    total = sum(whole[item].values())\n",
    "    whole[item] = {k: v / total for k, v in whole[item].items()}\n",
    "        \n",
    "def bigramLM(df):\n",
    "    transition = defaultdict(dict)\n",
    "    for line in tqdm(df.body): \n",
    "        prev_word = None\n",
    "        for word in line:\n",
    "            if not prev_word:\n",
    "                prev_word = 'BOS'\n",
    "            transition[prev_word][word] = transition[prev_word].get(word, 1)\n",
    "            prev_word = word\n",
    "        transition[prev_word]['EOS'] = transition[prev_word].get('EOS', 1)   \n",
    "        \n",
    "    for line in tqdm(df.title): \n",
    "        prev_word = None\n",
    "        for word in line:\n",
    "            if not prev_word:\n",
    "                prev_word = 'BOS'\n",
    "            transition[prev_word][word] = transition[prev_word].get(word, 1)\n",
    "            prev_word = word\n",
    "        transition[prev_word]['EOS'] = transition[prev_word].get('EOS', 1) \n",
    "        \n",
    "    _ = list(map(lambda item: freq_to_prob(transition, item), transition))\n",
    "    # return transposed dataframe so that each row index represent the prev_words\n",
    "    return pd.DataFrame(transition).T.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample run with train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv('reuters_train.csv')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 13530\n"
     ]
    }
   ],
   "source": [
    "vocab = generate_vocab(df, include_body=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13530/13530 [44:40<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "H_given_D = p_w_H_given_D(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.34, 8: 0.198, 5: 0.11, 6: 0.258, 9: 0.063, 4: 0.024, 10: 0.007}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_prob(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5013.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 83536.90it/s]\n"
     ]
    }
   ],
   "source": [
    "T = bigramLM(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in      0.333333\n",
       "of      0.333333\n",
       "dart    0.333333\n",
       "Name: millions, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.loc['millions',:][T.loc['millions',:]!= 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(doc, headline_len=6, H_given_D=H_given_D, transition=T):\n",
    "    # Generate vocab for headline candidates words\n",
    "    vocab = list(set(doc))\n",
    "    # F to store probabilities and B to store backpointers\n",
    "    F = pd.DataFrame(columns=range(headline_len), index=vocab).fillna(0)\n",
    "    B = pd.DataFrame(columns=range(headline_len), index=vocab).fillna(-1)\n",
    "    # Forward Path\n",
    "    for word in vocab:\n",
    "        F.loc[word, 0] = H_given_D.get(word, 1e-5) * T.loc['BOS', word]\n",
    "    for t in range(1, headline_len):\n",
    "        for i, word in enumerate(vocab):\n",
    "            max_prob, max_index = -1, -1\n",
    "            for j, prev_word in enumerate(vocab):\n",
    "                prob = H_given_D.get(word, 1e-5) * T.loc[prev_word, word] * F.loc[prev_word, t-1]\n",
    "                if prob > max_prob:\n",
    "                    max_prob, max_index = prob, j\n",
    "                    F.iloc[i, t] = max_prob\n",
    "                    B.iloc[i, t] = max_index\n",
    "    # Backtracking\n",
    "    pointer = np.argmax(F.iloc[:,-1])\n",
    "    pos_seq = [vocab[pointer]]\n",
    "    for i in range(headline_len-1, 0, -1):\n",
    "        pointer = B.iloc[pointer, i]\n",
    "        pos_seq.insert(0, vocab[pointer])\n",
    "    return pos_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sapporo', 'breweries', 'ltd', 'year', 'notes']\n"
     ]
    }
   ],
   "source": [
    "for doc in df.body[:1]:\n",
    "    print(Viterbi(doc, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sapporo', 'breweries', 'ltd', 'and', '10014', 'issue']\n"
     ]
    }
   ],
   "source": [
    "for doc in df.body[:1]:\n",
    "    print(Viterbi(doc, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_log(doc, headline_len=6, H_given_D=H_given_D, transition=T):\n",
    "    # Generate vocab for headline candidates words\n",
    "    vocab = list(set(doc))\n",
    "    # F to store probabilities and B to store backpointers\n",
    "    F = pd.DataFrame(columns=range(headline_len), index=vocab).fillna(0)\n",
    "    B = pd.DataFrame(columns=range(headline_len), index=vocab).fillna(-1)\n",
    "    # Forward Path\n",
    "    for word in vocab:\n",
    "        F.loc[word, 0] = np.log(H_given_D.get(word, 1e-5)) + np.log(T.loc['BOS', word]+1e-5)\n",
    "    for t in range(1, headline_len):\n",
    "        for i, word in enumerate(vocab):\n",
    "            max_prob, max_index = float('-inf'), -1\n",
    "            for j, prev_word in enumerate(vocab):\n",
    "                prob = np.log(H_given_D.get(word, 1e-5)) + np.log(T.loc[prev_word, word]+1e-5) \\\n",
    "                + np.log(F.loc[prev_word, t-1]+1e-5)\n",
    "                if prob > max_prob:\n",
    "                    max_prob, max_index = prob, j\n",
    "                    F.iloc[i, t] = max_prob\n",
    "                    B.iloc[i, t] = max_index\n",
    "    # Backtracking\n",
    "    pointer = np.argmax(F.iloc[:,-1])\n",
    "    pos_seq = [vocab[pointer]]\n",
    "    for i in range(headline_len-1, 0, -1):\n",
    "        pointer = B.iloc[pointer, i]\n",
    "        pos_seq.insert(0, vocab[pointer])\n",
    "    return pos_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-3faf3e6957a8>:15: RuntimeWarning: invalid value encountered in log\n",
      "  + np.log(F.loc[prev_word, t-1]+1e-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corp', 'bank', 'corp', 'bank', 'corp', '\\\\x03']\n"
     ]
    }
   ],
   "source": [
    "for doc in df.body[:1]:\n",
    "    print(Viterbi_log(doc, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
